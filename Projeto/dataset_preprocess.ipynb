{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giulio/.virtualenvs/venv_c_o_w/local/lib/python2.7/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment.util import extract_unigram_feats, mark_negation\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_orig = list(df.columns)\n",
    "col_new = ['airline_sentiment', 'airline_sentiment_confidence', 'airline', 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Testing area\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "df = df[col_new]\n",
    "df_text = df[['airline_sentiment', 'text']]\n",
    "# test_text = df[['airline_sentiment', 'text']][:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_tweet(tweet):\n",
    "    #Convert to lower case\n",
    "    tweet = tweet.lower()\n",
    "    \"\"\"\n",
    "    #Convert www.* or https?://* to URL\n",
    "    tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','URL',tweet)\n",
    "    #Convert @username to AT_USER\n",
    "    tweet = re.sub('@[^\\s]+','AT_USER',tweet)\n",
    "    \"\"\"\n",
    "    #Remove www.* or https?://*\n",
    "    tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','',tweet)\n",
    "    #Replace @username with username\n",
    "    tweet = re.sub(r'@([^\\s]+)', r'\\1', tweet)\n",
    "    #Remove additional white spaces\n",
    "    tweet = re.sub('[\\s]+', ' ', tweet)\n",
    "    #Replace #word with word\n",
    "    tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet)\n",
    "    #trim\n",
    "    tweet = tweet.strip('\\'\"')\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Testing area\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "tweets_data = []\n",
    "for text in df_text['text']:\n",
    "# for text in test_text['text']:\n",
    "    preproc_text = preprocess_tweet(text)\n",
    "    tokenized_text = nltk.word_tokenize(preproc_text.decode('utf-8'))\n",
    "    for i, token in enumerate(tokenized_text):\n",
    "        tokenized_text[i] = token.encode('utf-8')\n",
    "    tweets_data.append(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Testing area\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "for i, row in enumerate(tweets_data):\n",
    "    tweets_data[i] = (row, df_text['airline_sentiment'][i])\n",
    "#     tweets_data[i] = (row, test_text['airline_sentiment'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Testing area\n",
    "\"\"\"\n",
    "\n",
    "training_docs = tweets_data[:10000]\n",
    "testing_docs = tweets_data[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentim_analyzer = SentimentAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_words_neg = sentim_analyzer.all_words([mark_negation(doc) for doc in training_docs])\n",
    "unigram_feats = sentim_analyzer.unigram_word_feats(all_words_neg, min_freq=4)\n",
    "sentim_analyzer.add_feat_extractor(extract_unigram_feats, unigrams=unigram_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_set = sentim_analyzer.apply_features(training_docs)\n",
    "test_set = sentim_analyzer.apply_features(testing_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier\n"
     ]
    }
   ],
   "source": [
    "trainer = NaiveBayesClassifier.train\n",
    "classifier = sentim_analyzer.train(trainer, training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating NaiveBayesClassifier results...\n",
      "Accuracy: 0.825862068966\n",
      "F-measure [negative]: 0.89885024014\n",
      "F-measure [neutral]: 0.568405139834\n",
      "F-measure [positive]: 0.677716390424\n",
      "Precision [negative]: 0.894553881808\n",
      "Precision [neutral]: 0.594936708861\n",
      "Precision [positive]: 0.661870503597\n",
      "Recall [negative]: 0.903188066686\n",
      "Recall [neutral]: 0.544138929088\n",
      "Recall [positive]: 0.694339622642\n"
     ]
    }
   ],
   "source": [
    "for key,value in sorted(sentim_analyzer.evaluate(test_set).items()):\n",
    "    print('{0}: {1}'.format(key, value))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_c_o_w",
   "language": "python",
   "name": "venv_c_o_w"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
